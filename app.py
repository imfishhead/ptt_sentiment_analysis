# app.py

import streamlit as st
import pandas as pd
import datetime
import plotly.graph_objects as go
from data_fetcher import get_ptt_articles_from_db
from sentiment_analyzer import get_sentiment_model, analyze_sentiment_batch # å°å…¥ä½ æ›´æ–°å¾Œçš„å‡½æ•¸
from config import EMOTIONS_NAMES
import sqlite3

# --- Streamlit æ‡‰ç”¨ç¨‹å¼é…ç½® ---
st.set_page_config(
    page_title="PTT çœ‹æ¿æƒ…æ„Ÿåˆ†æå„€",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.title("ğŸ“Š PTT çœ‹æ¿æƒ…æ„Ÿè¶¨å‹¢åˆ†æå„€")
st.markdown("æ¢ç´¢ PTT çœ‹æ¿æ–‡ç« çš„æƒ…æ„Ÿæ³¢å‹•ï¼ŒæŒæ¡ç¤¾ç¾¤è„ˆå‹•ã€‚")

# --- è¼”åŠ©å‡½æ•¸ (ä¿æŒä¸è®Š) ---

@st.cache_data(show_spinner="â³ æ­£åœ¨èšåˆæƒ…æ„Ÿæ•¸æ“š...")
def aggregate_emotions_by_hour(df: pd.DataFrame) -> pd.DataFrame:
    """æ¯å°æ™‚èšåˆæƒ…æ„Ÿåˆ†æ•¸."""
    if df.empty:
        return pd.DataFrame()

    df['timestamp'] = pd.to_datetime(df['timestamp'])
    df = df.set_index('timestamp')

    for emo in EMOTIONS_NAMES:
        if emo not in df.columns:
            df[emo] = 0.0
        df[emo] = pd.to_numeric(df[emo], errors='coerce').fillna(0)

    agg_dict = {emo: 'mean' for emo in EMOTIONS_NAMES}
    hourly_emotions = df.resample('H').agg(agg_dict).fillna(0)
    return hourly_emotions

def plot_radar_chart(data_row: pd.Series, emotions: list) -> go.Figure:
    """ç¹ªè£½å…«è§’å‘é‡åœ– (é›·é”åœ–)ã€‚"""
    if data_row.empty or not any(data_row.get(emo, 0) > 0 for emo in emotions):
        fig = go.Figure()
        fig.add_annotation(
            text="ç„¡æƒ…æ„Ÿæ•¸æ“šå¯é¡¯ç¤ºï¼Œè«‹é¸æ“‡æœ‰å…§å®¹çš„æ™‚é–“é»ã€‚",
            x=0.5, y=0.5, showarrow=False, font_size=16, opacity=0.7
        )
        fig.update_layout(title="æƒ…æ„Ÿå…«è§’å‘é‡åœ–", title_x=0.5)
        return fig

    categories = [f"{EMOTION_NAMES_ZH.get(emo, emo)} {EMOTION_EMOJIS.get(emo, '')}" for emo in emotions]
    values = [data_row.get(emotion, 0) for emotion in emotions]
    
    # å‹•æ…‹è¨ˆç®—è»¸ç·šç¯„åœ
    max_value = max(values) if values else 0.1
    if max_value <= 0.1:
        # å¦‚æœæœ€å¤§å€¼å¾ˆå°ï¼Œè¨­å®šä¸€å€‹åˆé©çš„ç¯„åœ
        axis_max = 0.1
        tick_vals = [0, 0.02, 0.04, 0.06, 0.08, 0.1]
    elif max_value <= 0.5:
        # ä¸­ç­‰ç¯„åœ
        axis_max = 0.5
        tick_vals = [0, 0.1, 0.2, 0.3, 0.4, 0.5]
    else:
        # å¤§ç¯„åœ
        axis_max = 1.0
        tick_vals = [0, 0.25, 0.5, 0.75, 1.0]
    
    fig = go.Figure()
    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        name='æƒ…æ„Ÿç¨‹åº¦',
        marker=dict(color='deepskyblue', line=dict(color='dodgerblue', width=2)),
        opacity=0.8
    ))
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, axis_max],
                tickvals=tick_vals,
                ticktext=[f"{val:.3f}" for val in tick_vals],  # é¡¯ç¤ºä¸‰ä½å°æ•¸
                gridcolor='lightgray',
                linecolor='gray'
            ),
            bgcolor='white',
            gridshape='linear'
        ),
        showlegend=False,
        title="æƒ…æ„Ÿå…«è§’å‘é‡åœ–",
        title_x=0.5,
        font=dict(family="Arial, sans-serif", size=12)
    )
    return fig

def display_analysis_results(selected_board, hourly_data, articles_df, mode='exist'):
    """é¡¯ç¤ºåˆ†æçµæœçš„çµ±ä¸€å‡½æ•¸"""
    min_time = hourly_data.index.min().to_pydatetime()
    max_time = hourly_data.index.max().to_pydatetime()
    
    st.subheader(f"[{selected_board}] ä¸ƒå¤©æƒ…æ„Ÿè¶¨å‹¢åˆ†æ")
    st.subheader("ğŸ•°ï¸ æƒ…æ„Ÿè¶¨å‹¢æ™‚é–“è»¸")
    slider_needed = min_time != max_time
    if slider_needed:
        selected_time = st.slider(
            "é¸æ“‡æ™‚é–“é»ä»¥æŸ¥çœ‹è©²å°æ™‚çš„æƒ…æ„Ÿåˆ†ä½ˆ",
            min_value=min_time,
            max_value=max_time,
            value=max_time,
            step=datetime.timedelta(hours=1),
            format="YYYY/MM/DD HH:00",
            help="æ‹–å‹•æ»‘æ¡¿ä»¥æŸ¥çœ‹ä¸åŒæ™‚é–“é»çš„æ–‡ç« æƒ…æ„Ÿåˆ†ä½ˆã€‚",
            key=f"sentiment_time_slider_{mode}"
        )
    else:
        selected_time = min_time
        st.info(f"åƒ…æœ‰ä¸€å€‹æ™‚æ®µï¼š{min_time.strftime('%Y/%m/%d %H:00')}")

    time_diffs_td = hourly_data.index - selected_time
    time_diff_seconds = time_diffs_td.to_series().apply(lambda x: x.total_seconds()).abs()
    closest_time_index_loc = time_diff_seconds.argmin()
    closest_time_data = hourly_data.iloc[closest_time_index_loc]

    st.subheader("ğŸŒ å³æ™‚æƒ…æ„Ÿå…«è§’å‘é‡åœ–")
    st.plotly_chart(plot_radar_chart(closest_time_data, EMOTIONS_NAMES), use_container_width=True)

    st.subheader("ğŸ“ˆ éå»ä¸ƒå¤©æ¯å°æ™‚æƒ…æ„Ÿåˆ†æ•¸ (è¡¨æ ¼)")
    st.dataframe(hourly_data.reset_index().rename(columns={'index': 'æ™‚é–“'}), use_container_width=True, height=300)
    
    csv_data = hourly_data.to_csv(index=True).encode('utf-8')
    st.download_button(
        label="ä¸‹è¼‰æƒ…æ„Ÿæ•¸æ“š (CSV)",
        data=csv_data,
        file_name=f"{selected_board}_sentiment_data.csv",
        mime="text/csv",
        help="ä¸‹è¼‰ç•¶å‰çœ‹æ¿çš„æƒ…æ„Ÿæ•¸æ“šã€‚"
    )

    if st.button("é¡¯ç¤ºå·²æŠ“å–çš„åŸå§‹æ–‡ç« è³‡æ–™"):
        st.dataframe(articles_df, use_container_width=True, height=400)
        st.info(f"ç›®å‰å·²æŠ“å–ä¸¦ç´¯ç© {len(articles_df)} ç¯‡æ–‡ç« ï¼ˆå«æœ¬æ¬¡æ–°æŠ“å–ï¼‰")

# å¾ sentiment_analyzer å°å…¥é€™äº›é¡å¤–çš„æ˜ å°„ï¼Œç”¨æ–¼é¡¯ç¤º
from sentiment_analyzer import emotion_names_zh as EMOTION_NAMES_ZH
from sentiment_analyzer import emotion_emojis as EMOTION_EMOJIS

# --- SQLite å¿«å–è¼”åŠ©å‡½æ•¸ ---
def save_board_to_sqlite(board, df, db_path='ptt_cache.db'):
    conn = sqlite3.connect(db_path)
    df.to_sql(f'ptt_{board}', conn, if_exists='replace', index=False)
    conn.close()

def load_board_from_sqlite(board, db_path='ptt_cache.db'):
    conn = None
    try:
        conn = sqlite3.connect(db_path)
        # æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨
        cursor = conn.cursor()
        cursor.execute(f"SELECT name FROM sqlite_master WHERE type='table' AND name='ptt_{board}'")
        if cursor.fetchone() is None:
            # è¡¨æ ¼ä¸å­˜åœ¨ï¼Œå›å‚³ç©º DataFrame
            return pd.DataFrame()
        
        # åªè¼‰å…¥è¿‘ä¸ƒå¤©
        seven_days_ago = (datetime.datetime.now() - datetime.timedelta(days=7)).strftime('%Y-%m-%d')
        query = f"SELECT * FROM ptt_{board} WHERE timestamp >= '{seven_days_ago}'"
        df = pd.read_sql(query, conn, parse_dates=['timestamp'])
        return df
    except Exception as e:
        # ä»»ä½•éŒ¯èª¤éƒ½å›å‚³ç©º DataFrame
        return pd.DataFrame()
    finally:
        if conn:
            conn.close()

# --- CSV å‚™ç”¨æ•¸æ“šè®€å–å‡½æ•¸ ---
def load_csv_backup(board):
    """å¾å°ˆæ¡ˆç›®éŒ„è®€å– CSV å‚™ç”¨æ•¸æ“š"""
    import os
    import glob
    
    # å°‹æ‰¾ç¬¦åˆçœ‹æ¿åç¨±çš„ CSV æª”æ¡ˆ
    csv_patterns = [
        f"{board.lower()}_*.csv",
        f"{board}_*.csv", 
        f"*{board.lower()}*.csv",
        f"*{board}*.csv"
    ]
    
    for pattern in csv_patterns:
        csv_files = glob.glob(pattern)
        if csv_files:
            # æ‰¾åˆ°æª”æ¡ˆï¼Œè®€å–ç¬¬ä¸€å€‹
            csv_file = csv_files[0]
            try:
                st.info(f"ğŸ“ è®€å–å‚™ç”¨ CSV æª”æ¡ˆï¼š{csv_file}")
                df = pd.read_csv(csv_file, parse_dates=['timestamp'])
                
                # æª¢æŸ¥å¿…è¦çš„æ¬„ä½
                required_columns = ['timestamp', 'content', 'title', 'author', 'board']
                missing_columns = [col for col in required_columns if col not in df.columns]
                
                if missing_columns:
                    st.warning(f"CSV æª”æ¡ˆç¼ºå°‘å¿…è¦æ¬„ä½ï¼š{missing_columns}")
                    continue
                
                # å–æ¶ˆæ™‚é–“ç¯©é¸ï¼Œç›´æ¥è®€å–æ‰€æœ‰æ•¸æ“š
                if not df.empty:
                    st.success(f"âœ… æˆåŠŸè®€å– {len(df)} ç¯‡æ–‡ç« ï¼ˆä¾†è‡ª CSV å‚™ç”¨æ•¸æ“šï¼‰")
                    return df
                else:
                    st.warning("CSV æª”æ¡ˆæ˜¯ç©ºçš„")
                    
            except Exception as e:
                st.error(f"è®€å– CSV æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{str(e)}")
                continue
    
    st.warning("âŒ æ²’æœ‰æ‰¾åˆ°å¯ç”¨çš„ CSV å‚™ç”¨æ•¸æ“šæª”æ¡ˆ")
    return pd.DataFrame()

# --- å´é‚Šæ¬„æ§åˆ¶é … ---
with st.sidebar:
    st.header("è¨­å®šé¸é …")
    board_options = ['Gossiping', 'WomenTalk', 'Tech_Job', 'Boy-Girl', 'Stock', 'NBA']
    selected_board = st.selectbox("é¸æ“‡ PTT çœ‹æ¿", board_options, help="é¸æ“‡ä½ æ„Ÿèˆˆè¶£çš„ PTT çœ‹æ¿é€²è¡Œåˆ†æã€‚")

    today = datetime.date.today()
    start_date = today - datetime.timedelta(days=6)
    end_date = today
    st.write(f"åˆ†æå€é–“ï¼š{start_date} ~ {end_date}")

    # å•Ÿå‹•æ™‚è‡ªå‹•å¾ SQLite è¼‰å…¥ cache
    if 'articles_df_dict' not in st.session_state:
        st.session_state['articles_df_dict'] = {}
    if 'hourly_data_dict' not in st.session_state:
        st.session_state['hourly_data_dict'] = {}
    
    # ç§»é™¤è‡ªå‹•è¼‰å…¥ï¼Œåªåœ¨æŒ‰ä¸‹æŒ‰éˆ•æ™‚æ‰è¼‰å…¥è³‡æ–™

    # ä¾æ“šç›®å‰ dropdown é¸æ“‡é¡¯ç¤º cache æ•¸é‡
    cache_count = 0
    latest_time_str = "ç„¡"
    if selected_board in st.session_state['articles_df_dict'] and isinstance(st.session_state['articles_df_dict'][selected_board], pd.DataFrame):
        cache_count = len(st.session_state['articles_df_dict'][selected_board])
        if cache_count > 0:
            latest_time = st.session_state['articles_df_dict'][selected_board]['timestamp'].max()
            latest_time_str = latest_time.strftime('%Y/%m/%d %H:%M')
    st.write(f"ç›®å‰ Cache å·²æœ‰ {cache_count} ç¯‡æ–‡ç« ï¼Œæœ€æ–°æŠ“å–æ™‚é–“ï¼š{latest_time_str}")

    if st.button("ğŸ”„ æŠ“å–ä¸¦åˆ†ææœ€æ–°æ–‡ç« ", help=f"é»æ“Šä»¥ç²å– {selected_board} çœ‹æ¿éå»ä¸ƒå¤©çš„æ–‡ç« ï¼Œä¸¦é‡æ–°é€²è¡Œæƒ…æ„Ÿåˆ†æã€‚", use_container_width=True):
        st.session_state['trigger_fetch'] = True
        st.session_state['board_for_fetch'] = selected_board
        st.session_state['start_date'] = start_date
        st.session_state['end_date'] = end_date
        st.success("å·²æ’ç¨‹æ•¸æ“šæŠ“å–èˆ‡åˆ†æï¼è«‹ç¨å€™...")

# --- ä¸»å…§å®¹å€åŸŸ ---

if st.session_state.get('trigger_fetch', False):
    # ä¸è¦æ¸…ç©º cacheï¼Œä¿ç•™ç”¨æ–¼å¢é‡æŠ“å–
    st.session_state['hourly_data_dict'][selected_board] = pd.DataFrame()

    # è¼‰å…¥ç¾æœ‰è³‡æ–™ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    if selected_board not in st.session_state['articles_df_dict']:
        st.session_state['articles_df_dict'][selected_board] = load_board_from_sqlite(selected_board)

    sentiment_model_placeholder = get_sentiment_model()

    # å–å¾—ç›®å‰ cache æœ€æ–°æ–‡ç« æ™‚é–“
    last_time = None
    if selected_board in st.session_state['articles_df_dict'] and not st.session_state['articles_df_dict'][selected_board].empty:
        last_time = st.session_state['articles_df_dict'][selected_board]['timestamp'].max()
        st.info(f"ç¾æœ‰ cache æœ€æ–°æ–‡ç« æ™‚é–“ï¼š{last_time}")
    
    st.info(f"é–‹å§‹å‘¼å«çˆ¬èŸ²å‡½æ•¸ï¼šget_ptt_articles_from_db({st.session_state['board_for_fetch']}, {last_time})")
    
    articles_df = get_ptt_articles_from_db(
        board=st.session_state['board_for_fetch'],
        last_time=last_time
    )
    
    st.info(f"çˆ¬èŸ²å‡½æ•¸åŸ·è¡Œå®Œæˆï¼Œå›å‚³ DataFrame å¤§å°ï¼š{len(articles_df)} è¡Œ")

    # å¦‚æœçˆ¬å–å¤±æ•—ï¼Œå˜—è©¦è®€å– CSV å‚™ç”¨æ•¸æ“š
    if articles_df.empty:
        st.warning("âš ï¸ çˆ¬å–å¤±æ•—ï¼Œå˜—è©¦è®€å– CSV å‚™ç”¨æ•¸æ“š...")
        articles_df = load_csv_backup(selected_board)
        
        if not articles_df.empty:
            st.success("âœ… æˆåŠŸä½¿ç”¨ CSV å‚™ç”¨æ•¸æ“šï¼")
        else:
            st.error("âŒ çˆ¬å–å¤±æ•—ä¸”ç„¡å¯ç”¨å‚™ç”¨æ•¸æ“šï¼Œè«‹æª¢æŸ¥ç¶²è·¯é€£ç·šæˆ–æä¾› CSV æª”æ¡ˆ")
            st.session_state['hourly_data_dict'][selected_board] = pd.DataFrame()
            st.session_state['articles_df_dict'][selected_board] = pd.DataFrame()
            st.session_state['trigger_fetch'] = False
            st.stop()

    if not articles_df.empty:
        st.info("é–‹å§‹æƒ…æ„Ÿåˆ†æ...")
        articles_df = analyze_sentiment_batch(articles_df, sentiment_model_placeholder)
        hourly_data = aggregate_emotions_by_hour(articles_df)
        st.session_state['hourly_data_dict'][selected_board] = hourly_data
        st.session_state['articles_df_dict'][selected_board] = articles_df
        save_board_to_sqlite(selected_board, articles_df)  # å¯«å…¥ SQLite
        st.success("âœ… æ–‡ç« æŠ“å–èˆ‡æƒ…æ„Ÿåˆ†æå®Œæˆï¼")
        display_analysis_results(selected_board, hourly_data, articles_df,'analyze')
    else:
        st.warning("âš ï¸ æ²’æœ‰æ‰¾åˆ°ç¬¦åˆæ¢ä»¶çš„æ–‡ç« ï¼Œè«‹å˜—è©¦å…¶ä»–çœ‹æ¿æˆ–æ™‚é–“ç¯„åœã€‚")
        st.session_state['hourly_data_dict'][selected_board] = pd.DataFrame()
        st.session_state['articles_df_dict'][selected_board] = pd.DataFrame()
    st.session_state['trigger_fetch'] = False
elif (
    ('hourly_data_dict' not in st.session_state or selected_board not in st.session_state['hourly_data_dict'] or st.session_state['hourly_data_dict'][selected_board].empty)
    and ('articles_df_dict' not in st.session_state or selected_board not in st.session_state['articles_df_dict'] or st.session_state['articles_df_dict'][selected_board].empty)
    and not st.session_state.get('trigger_fetch', False)
):
    st.info("æ­¡è¿ä½¿ç”¨ï¼è«‹å¾å·¦å´é¸æ“‡çœ‹æ¿ï¼Œç„¶å¾Œé»æ“Šã€ŒæŠ“å–ä¸¦åˆ†ææœ€æ–°æ–‡ç« ã€æŒ‰éˆ•é–‹å§‹ã€‚")

st.markdown("---")
st.caption("æ•¸æ“šä¾†æºï¼šPTTã€‚æƒ…æ„Ÿåˆ†æçµæœä¾†è‡ªè©å…¸èˆ‡è¦å‰‡ã€‚")